Matching process requirements (full logic)
0) Inputs

User scope: app_user_id

Model scope: model_id

Model JSON (from match_job.model_json or mdm_models.config_json) contains:

matchFieldCodes (e.g., ["f01","f02","f03"])

per-field:

weight (sum of weights across matchFieldCodes = 1.0)

matchThreshold (field-level gate)

model-level:

matchThreshold (strong match)

possibleThreshold (possible match)

Data tables:

source_input = incoming records for app_user_id

recon_cluster = clustered history for (app_user_id, model_id)

1) Core scoring rules

1.1 Field-level similarity

For any two values (a,b):

compute sim = conservative_similarity(a,b) where:

sim = 1 - lev(a,b) / min(len(a),len(b)) clamped to [0..1]

Field passes if: sim >= field.matchThreshold

1.2 Model-level score (weighted gated)

For each match field i:

compute (pass_i, sim_i) via field-level rule

if pass_i == True: contribution = sim_i * weight_i

if pass_i == False: contribution = 0

Total model score:

score = sum(contribution_i)

Weight = 0 means field has no effect on the model score.

1.3 Pair classification by score

If score >= model.matchThreshold → strong match

Else if possibleThreshold <= score < matchThreshold → possible match

Else → no match

2) Candidate generation (blocking)

Goal: avoid O(N²) scans; restrict candidate comparisons.

2.1 Blocking fields selection

Use matchFieldCodes sorted by weight desc

Use top 2 fields by default; if missing values, fall back to next weighted fields.

2.2 Adaptive prefix blocking

Normalize values: lower, trim, strip punctuation, collapse whitespace.

Build block keys using prefixes of the top weighted fields.

Tighten progressively until candidate count ≤ target (e.g., 1000):

1+1, then 2+1, then 2+2, then 3+2, then keep increasing.

Candidate set is produced for each record using this adaptive logic.

If no blockers available, fall back to a capped scan (limited size).

3) Two operating modes
Mode A: Initial run (bootstrap) — when recon_cluster is empty for (app_user_id, model_id)

Objective: cluster the incoming batch against itself.

A1) Build strong-match clusters (matchThreshold)

For each record r in the batch:

Generate candidate records from the batch using blocking.

For each candidate c:

compute model score(r,c)

if score >= matchThreshold: create a strong match link between r and c.

Build clusters as connected components of strong links (transitive closure).

A2) Assign cluster_id to strong clusters

Each strong cluster gets one cluster_id (UUID).

All records in those clusters:

cluster_id = cluster.cluster_id

match_status = "match"

A3) “Find home” for remaining records (possibleThreshold)

For any record not in a strong cluster:

Find its best possible cluster candidate using model score:

consider possible links to any record already assigned to a cluster (or to any record; cluster-level pick resolves later)

choose the candidate cluster with highest score

tie-breaker: smallest cluster_id

If best possible score ≥ possibleThreshold:

assign cluster_id = best_candidate_cluster_id

set match_status = "exception"

write an exception row (record → candidate cluster + score)

If no possible candidate exists:

create a new single-record cluster:

new cluster_id

match_status = "no_match"

A4) Write outputs

Insert all records into recon_cluster with:

cluster_id

match_status in (match, exception, no_match)

original fields source_name/source_id/f01..f20/audit

Upsert cluster_map for (source_name, source_id) → cluster_id.

Mode B: Incremental run — when recon_cluster already has rows

Objective: assign new incoming records into existing clusters, or create new ones.

B1) Identify new records

Process only source_input rows that do not exist in recon_cluster for the same (app_user_id, model_id, source_name, source_id).

B2) For each new record, find best home

Generate candidate clusters from recon_cluster using blocking.

Compute model score against candidates.

Pick best candidate cluster:

max score

tie-breaker: smallest cluster_id

B3) Assign + classify

If best score ≥ matchThreshold:

assign that cluster_id

match_status = "match"

Else if best score ≥ possibleThreshold:

assign that cluster_id

match_status = "exception"

write exception row

Else:

create new cluster_id

match_status = "no_match"

B4) Persist

Insert into recon_cluster

Upsert cluster_map

Insert exception rows when status = exception

4) Tie-breaking

When multiple candidate clusters have equal best score:

choose the one with smallest cluster_id.

5) Non-negotiable outputs

Every record gets a cluster_id:

either from a strong cluster, best possible home, or a new single-record cluster.

Every record has match_status:

match, exception, or no_match.





##########  How the dynamic candidate selection works ##########

Pick blocking fields dynamically: take match fields sorted by weight (highest weight first), and use the first ones that actually have values (it will consider more than 2 if earlier ones are blank). 

worker

 

matching process

Start with short prefixes (e.g., first character of field1, plus first character of field2 if using two fields). 

worker

 

matching process

Count candidates returned by that prefix block.

If candidate count is ≤ target, stop and score those.

If candidate count is > target, tighten the block by increasing prefix lengths in the spec pattern: 1+1 → 2+1 → 2+2 → 3+2 → 3+3 → … until it’s small enough (or until max prefix length is reached). 

worker

 

matching process

If there are no usable blocking values, it falls back to a capped scan (limited to the target size). 

worker

 

matching process